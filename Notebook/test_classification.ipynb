{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9d4947",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697c899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import cv2 as cv \n",
    "from PIL import Image \n",
    "\n",
    "import time\n",
    "\n",
    "#from pycoral.adapters import classify, common\n",
    "#from pycoral.utils.edgetpu import make_interpreter\n",
    "#from pycoral.utils.dataset import read_label_file\n",
    "\n",
    "from tflite_runtime.interpreter import Interpreter\n",
    "from tflite_runtime.interpreter import load_delegate\n",
    "\n",
    "from reachy_sdk import ReachySDK\n",
    "\n",
    "from reachy_sdk.trajectory import goto\n",
    "from reachy_sdk.trajectory.interpolation import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e9edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reachy = ReachySDK('localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c43c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = '/home/reachy/Desktop/quant/model_quant.tflite'\n",
    "path_label = '/home/reachy/Desktop/quant/quant.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = '/home/reachy/dev/reachy-tictactoe/reachy_tictactoe/models/ttt-boxes.tflite'\n",
    "path_label = '/home/reachy/dev/reachy-tictactoe/reachy_tictactoe/models/ttt-boxes.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b3e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interpreter = make_interpreter(path_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "labels = read_label_file(path_label)\n",
    "print(labels)\n",
    "size = common.input_size(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_cases = np.array((\n",
    "    ((81, 166, 260, 340), #Coordinates first board cases (top-left corner) (Xbl, Xbr, Ytr, Ybr)\n",
    "     (166, 258, 260, 340), #Coordinates second board cases\n",
    "     (258, 349, 260, 340),),\n",
    "\n",
    "    ((74, 161, 340, 432),\n",
    "     (161, 261, 340, 432),\n",
    "     (261, 360, 340, 432),),\n",
    "\n",
    "    ((65, 161, 432, 522),\n",
    "     (161, 266, 432, 522),\n",
    "     (266, 365, 432, 522),),\n",
    "))\n",
    "# left, right, top, bottom\n",
    "board_rect = np.array((\n",
    "    74, 384, 216, 483,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60548865",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = reachy.right_camera.wait_for_new_frame()\n",
    "height, width = np.shape(im)[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0962f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv.VideoWriter('tuto_classification1.avi',cv.VideoWriter_fourcc('M','J','P','G'), 10, (width,height))\n",
    "\n",
    "reachy.turn_on('head')\n",
    "reachy.head.look_at(x=1, y=0, z=0, duration=1.5)  \n",
    "time.sleep(1.5)\n",
    "\n",
    "reachy.head.look_at(0.5, 0, -0.5, duration=1.25)\n",
    "time.sleep(1.25)\n",
    "start = time.time()\n",
    "\n",
    "fps_count = 0\n",
    "\n",
    "while time.time() - start < 15:\n",
    "    \n",
    "    im = reachy.right_camera.wait_for_new_frame()\n",
    "    out = im.copy()\n",
    "\n",
    "    for row in range(3):\n",
    "        for col in range(3):\n",
    "            lx, rx, ly, ry = board_cases[row, col]\n",
    "            pil_img = Image.fromarray(out[ly:ry, lx:rx]).convert('RGB').resize(size, Image.ANTIALIAS)\n",
    "            pil_img.save(f'/home/reachy/Desktop/image{row}{col}.png')\n",
    "            common.set_input(interpreter, pil_img)\n",
    "            interpreter.invoke()\n",
    "            result = classify.get_classes(interpreter, top_k=3, score_threshold=0.8)\n",
    "            print(f' resultat ={result}')\n",
    "            if result :\n",
    "                label = labels.get(result[0].id)\n",
    "                cv.putText(out, label, (int((lx+rx)/2)-30, int((ly+ry)/2)), cv.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0), 2)\n",
    "                cv.rectangle(out, (lx, ly), (rx, ry), (0, 255, 0), 5)\n",
    "    video.write(out)        \n",
    "            \n",
    "video.release()\n",
    "\n",
    "reachy.head.look_at(0.5, 0, 0, duration=1)\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed385e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return {i: line.strip() for i, line in enumerate(f.readlines())}\n",
    "\n",
    "\n",
    "def set_input_tensor(interpreter, image):\n",
    "    tensor_index = interpreter.get_input_details()[0]['index']\n",
    "    input_tensor = interpreter.tensor(tensor_index)()[0]\n",
    "    input_tensor[:, :] = image\n",
    "\n",
    "def classify_image(interpreter, image, top_k=3):\n",
    "    \"\"\"Returns a sorted array of classification results.\"\"\"\n",
    "    set_input_tensor(interpreter, image)\n",
    "    interpreter.invoke()\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    output = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
    "    print(f'output = {output}')\n",
    "\n",
    "    # If the model is quantized (uint8 data), then dequantize the results\n",
    "    if output_details['dtype'] == np.uint8:\n",
    "        print('passee')\n",
    "        scale, zero_point = output_details['quantization']\n",
    "        output = scale * (output - zero_point)\n",
    "\n",
    "    ordered = np.argpartition(-output, top_k)\n",
    "    return [(i, output[i]) for i in ordered[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb34987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "output = [[ -83  -58   48    4]\n",
      " [ -49  -71  122   42]\n",
      " [ -76  -91   17   34]\n",
      " [ -70  -77   57   71]\n",
      " [ -97  -87   58   33]\n",
      " [ -16 -110   93  -38]\n",
      " [ -62  -71   13   60]\n",
      " [-128  -22   67   90]\n",
      " [ -64 -115   54   20]\n",
      " [ -30   -7   99   68]]\n",
      " resultat =[(array([2, 3, 1, 0]), array([[-76, -91,  17,  34],\n",
      "       [-70, -77,  57,  71],\n",
      "       [-49, -71, 122,  42],\n",
      "       [-83, -58,  48,   4]], dtype=int8)), (array([2, 3, 0, 1]), array([[-76, -91,  17,  34],\n",
      "       [-70, -77,  57,  71],\n",
      "       [-83, -58,  48,   4],\n",
      "       [-49, -71, 122,  42]], dtype=int8)), (array([2, 3, 0, 1]), array([[-76, -91,  17,  34],\n",
      "       [-70, -77,  57,  71],\n",
      "       [-83, -58,  48,   4],\n",
      "       [-49, -71, 122,  42]], dtype=int8))]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4055387e41f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' resultat ={results}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#print(f' resultat ={labels[label_id]}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "labels = load_labels(path_label)\n",
    "\n",
    "interpreter = Interpreter(path_model)\n",
    "#interpreter = Interpreter(path_model, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\n",
    "interpreter.allocate_tensors()\n",
    "_, height, width, _ = interpreter.get_input_details()[0]['shape']\n",
    "\n",
    "reachy.turn_on('head')\n",
    "reachy.head.look_at(x=1, y=0, z=0, duration=1.5)  \n",
    "time.sleep(1.5)\n",
    "\n",
    "reachy.head.look_at(0.5, 0, -0.5, duration=1.25)\n",
    "time.sleep(1.25)\n",
    "start = time.time()\n",
    "\n",
    "fps_count = 0\n",
    "nb=0\n",
    "\n",
    "while time.time() - start < 15:\n",
    "    \n",
    "    im = reachy.right_camera.wait_for_new_frame()\n",
    "    print(type(im))\n",
    "    out = im.copy()\n",
    "    pil_img = Image.fromarray(out).convert('RGB').resize((width, height),Image.ANTIALIAS)\n",
    "    #pil_img = Image.fromarray(out[ly:ry, lx:rx]).convert('RGB').resize(size, Image.ANTIALIAS)\n",
    "    pil_img.save(f'/home/reachy/Desktop/image{nb}.png')\n",
    "    #common.set_input(interpreter, pil_img)\n",
    "    #interpreter.invoke()\n",
    "    results = classify_image(interpreter, pil_img)\n",
    "    label_id, prob = results[0]\n",
    "    #result = classify.get_classes(interpreter, top_k=3, score_threshold=0.8)\n",
    "    print(f' resultat ={results}')\n",
    "    #print(f' resultat ={labels[label_id]}')\n",
    "    cv.putText(out,labels[label_id], cv.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0), 2)\n",
    "    nb = nb+1\n",
    "\n",
    "reachy.head.look_at(0.5, 0, 0, duration=1)\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reachy.turn_on('head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c00513",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reachy.head.look_at(1, 0, 0, duration=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae373ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
